{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3113,
     "status": "ok",
     "timestamp": 1635811753910,
     "user": {
      "displayName": "Sathyanarayanan Vasudevan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18152865855978230831"
     },
     "user_tz": -330
    },
    "id": "SWhX3w0JK0w7"
   },
   "outputs": [],
   "source": [
    "#importing the required packages\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt  \n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1635811753912,
     "user": {
      "displayName": "Sathyanarayanan Vasudevan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18152865855978230831"
     },
     "user_tz": -330
    },
    "id": "QnTEvwDQMMxw"
   },
   "outputs": [],
   "source": [
    "#specifying the path \n",
    "DATASET_PATH = \"\\\\Users\\\\vvsat\\\\Documents\\\\machine learning\\\\Alzheimer_s\\\\Dataset\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1635811753914,
     "user": {
      "displayName": "Sathyanarayanan Vasudevan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18152865855978230831"
     },
     "user_tz": -330
    },
    "id": "u1lbLmEdMsTC"
   },
   "outputs": [],
   "source": [
    "#defining the classes of the dataset \n",
    "disease_cls = ['MildDemented','ModerateDemented','NonDemented','VeryMildDemented']  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWqoikd4YUP7"
   },
   "source": [
    "SPLITTTING THE IMAGES INTO TRAIN, TEST AND VALID DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18870,
     "status": "ok",
     "timestamp": 1635811775274,
     "user": {
      "displayName": "Sathyanarayanan Vasudevan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18152865855978230831"
     },
     "user_tz": -330
    },
    "id": "8xXGHVOIlheA",
    "outputId": "ba9061b6-8e28-49c3-d622-4fe5b2a955f8"
   },
   "outputs": [],
   "source": [
    "#splitting the images into train, test and valid datasets with 70, 15 and 15 percentage weightage\n",
    "import splitfolders \n",
    "splitfolders.ratio(DATASET_PATH, output=\"split\", seed=1, ratio=(.7, .15, .15), group_prefix=None)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hqNNOjeQ_46"
   },
   "source": [
    "IMAGE DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1635811775277,
     "user": {
      "displayName": "Sathyanarayanan Vasudevan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18152865855978230831"
     },
     "user_tz": -330
    },
    "id": "2XANDdVKUSjB"
   },
   "outputs": [],
   "source": [
    "#importing the required packages \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 579,
     "status": "ok",
     "timestamp": 1635811775846,
     "user": {
      "displayName": "Sathyanarayanan Vasudevan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18152865855978230831"
     },
     "user_tz": -330
    },
    "id": "25OOia7FUd2m",
    "outputId": "26c4444e-2746-44d0-e6f1-ba84c476d108"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vvsat\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:349: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\vvsat\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:356: UserWarning: This ImageDataGenerator specifies `samplewise_std_normalization`, which overrides setting of `samplewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5848 images belonging to 4 classes.\n",
      "Found 1766 images belonging to 4 classes.\n",
      "Found 1787 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "#applying the neccessary preprocessing required for this data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                   featurewise_std_normalization=True,\n",
    "                                   samplewise_std_normalization=True,\n",
    "                                   brightness_range=[0.3,0.5],\n",
    "                                   zoom_range = 0.05, \n",
    "                                   horizontal_flip = True) \n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                        featurewise_std_normalization=True,\n",
    "                                        samplewise_std_normalization=True,\n",
    "                                        brightness_range=[0.3,0.5],\n",
    "                                        zoom_range = 0.05, \n",
    "                                        horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  featurewise_std_normalization=True,\n",
    "                                  samplewise_std_normalization=True,\n",
    "                                  brightness_range=[0.3,0.5],\n",
    "                                  zoom_range = 0.05, \n",
    "                                  horizontal_flip = True)\n",
    "\n",
    "\n",
    "# Read the training sample and set the batch size \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'split/train/',\n",
    "        target_size=(128, 128),\n",
    "        batch_size=32,\n",
    "        seed=100,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Read Validation data from directory and define target size with batch size\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'split/val/',\n",
    "        target_size=(128, 128),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        seed=500, \n",
    "        shuffle=False)\n",
    "\n",
    "# Read test data from directory and define target size with batch size\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'split/test/',\n",
    "        target_size=(128, 128),\n",
    "        batch_size=32,\n",
    "        seed=1000,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITEQZMJHfqbO"
   },
   "source": [
    "MODEL BUILDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLMHOGGjDDYc"
   },
   "source": [
    "HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tBHn5wKsd1Y5"
   },
   "outputs": [],
   "source": [
    "#importing the required packages\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras import regularizers \n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D,BatchNormalization,Dropout,Conv2D,MaxPool2D      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FREEZING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fMPvu-5Md1Y7"
   },
   "outputs": [],
   "source": [
    "#defining a function with all the hyperparameters for tuning  \n",
    "def model_builder(hp):    \n",
    "    #defining the hyperparameters units, dropout, lr and weight decay\n",
    "    hp_units = hp.Int('units', min_value=256, max_value=512, step=10)\n",
    "    hp_dropout = hp.Choice('drop_out', values=[0.2, 0.3, 0.5, 0.7, 0.8]) \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[0.0001, 0.001, 0.01, 0.05, 0.1])\n",
    "    hp_weight_decay = hp.Choice('weight_decay', values=[0.0001, 0.001, 0.01, 0.05, 0.1])   \n",
    "    hp_weight_decay_2 = hp.Choice('weight_decay_2', values=[0.0001, 0.001, 0.01, 0.05, 0.1])  \n",
    "    # building a sequential model \n",
    "    model = Sequential()  \n",
    "    model.add(VGG19(include_top=False,input_tensor=None,input_shape=(128,128,3),\n",
    "                     pooling='avg',classes=4,weights='imagenet'))     \n",
    "    #freezing the pretrained layers\n",
    "    model.layers[0].trainable = False    \n",
    "    model.add(Flatten())  \n",
    "    model.add(Dropout(rate = hp_dropout))   \n",
    "    #fully connected layers\n",
    "    model.add(Dense(units = hp_units, activation='relu', kernel_regularizer=regularizers.l2(l2 = hp_weight_decay)))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Dense(32, kernel_regularizer=regularizers.l2(l2 = hp_weight_decay_2)))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(8))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.summary()  \n",
    "    \n",
    "                                     \n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "                  loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=[['acc'], tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]) \n",
    "\n",
    "    return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ax5iRSAhXJ_I"
   },
   "outputs": [],
   "source": [
    "import keras_tuner as kt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zY475JOiW76I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project alzheimer_vgg19_2\\intro_to_kt\\oracle.json\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Functional)           (None, 512)               20024384  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 20,199,644\n",
      "Trainable params: 175,260\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Reloading Tuner from alzheimer_vgg19_2\\intro_to_kt\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "#creating a hyperband tuner using keras tuner \n",
    "tuner = kt.Hyperband(model_builder, \n",
    "                     objective='acc', \n",
    "                     max_epochs=10, \n",
    "                     hyperband_iterations=10,        \n",
    "                     factor=50,\n",
    "                     directory='alzheimer_vgg19_2',\n",
    "                     project_name='intro_to_kt')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0P8Ct8VZXL-B"
   },
   "outputs": [],
   "source": [
    "#early stopping callback to stop the model when the loss shoots up \n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, mode = 'auto', restore_best_weights=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Syofi2qiVkgi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "best number of units for the dense layer 266\n",
      "best dropout 0.2\n",
      "best learning rate 0.0001\n",
      "best weight decay 0.0001\n",
      "best weight decay 2 0.1\n"
     ]
    }
   ],
   "source": [
    "#run the hyperband tuner\n",
    "tuner.search(train_generator, callbacks=[stop_early])    \n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print('best number of units for the dense layer', best_hps.get('units'))\n",
    "print('best dropout', best_hps.get('drop_out'))\n",
    "print('best learning rate', best_hps.get('learning_rate'))\n",
    "print('best weight decay', best_hps.get('weight_decay'))\n",
    "print('best weight decay 2', best_hps.get('weight_decay_2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATING A NEW SEQUENTIAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Functional)           (None, 512)               20024384  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 266)               136458    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               34176     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 20,206,054\n",
      "Trainable params: 181,670\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# building the final sequential model \n",
    "model = Sequential()  \n",
    "#adding VGG19 with the imagenet weights\n",
    "model.add(VGG19(include_top=False,input_tensor=None,input_shape=(128,128,3),\n",
    "                     pooling='avg',classes=4,weights='imagenet')) \n",
    "#freezing the pretrained layers\n",
    "model.layers[0].trainable = False\n",
    "#flattening the outputs of the model    \n",
    "model.add(Flatten())  \n",
    "#dropping out the a percentage of the model weights\n",
    "model.add(Dropout(rate = best_hps.get('drop_out')))   \n",
    "#fully connected layer\n",
    "model.add(Dense(units = best_hps.get('units'), activation='relu', \n",
    "                kernel_regularizer=regularizers.l2(l2 = best_hps.get('weight_decay'))))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(32, kernel_regularizer=regularizers.l2(l2 = best_hps.get('weight_decay_2'))))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.summary()                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compliling the model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate = best_hps.get('learning_rate')),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[['acc'], tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model\n",
    "history = model.fit(train_generator, \n",
    "      steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "      epochs=30, \n",
    "      validation_data=validation_generator, \n",
    "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "      verbose=1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNFREEZING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Functional)           (None, 512)               20024384  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 266)               136458    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               34176     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 20,206,054\n",
      "Trainable params: 20,206,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#unfreezing the pretrained layers\n",
    "model.layers[0].trainable = True\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compliling the model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate = best_hps.get('learning_rate')),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[['acc'], tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training the model\n",
    "history = model.fit(train_generator, \n",
    "      steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "      epochs=30, \n",
    "      validation_data=validation_generator, \n",
    "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "      verbose=1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YZeZC_qqazZ"
   },
   "source": [
    "SAVING THE MODEL AND ITS WEIGHTS AFTER HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ldwQxrwPrWvW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vvsat\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: \\Users\\vvsat\\Documents\\machine learning\\Alzheimer_s\\models\\save\\prod\\assets\n"
     ]
    }
   ],
   "source": [
    "#saving the model\n",
    "model.save('\\\\Users\\\\vvsat\\\\Documents\\\\machine learning\\\\Alzheimer_s\\\\models\\\\save\\\\prod')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lU3_Py4Tqazj"
   },
   "outputs": [],
   "source": [
    "#saving the model in both hdf5 format\n",
    "model.save('model_after_hpt_vgg19.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "VkcD3i33sLKh",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#loading the model\n",
    "model = keras.models.load_model('model_after_hpt_resnet101.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8v_lEvcHpSr"
   },
   "source": [
    "PLOTTING THE GRAPHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3oKDhC-QmvFE"
   },
   "outputs": [],
   "source": [
    "train_acc = history.history['acc'] \n",
    "val_acc = history.history['val_acc']\n",
    "train_loss = history.history['loss'] \n",
    "val_loss = history.history['val_loss'] \n",
    "train_precision = history.history['precision_2'] \n",
    "val_precision = history.history['val_precision_2'] \n",
    "train_recall = history.history['recall_2']\n",
    "val_recall = history.history['val_recall_2']\n",
    "train_auc = history.history['auc_2']\n",
    "val_auc = history.history['val_auc_2'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-My1lI9qmvF6"
   },
   "outputs": [],
   "source": [
    "epochs = range(len(train_acc)) \n",
    "plt.plot(epochs, train_acc, 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, train_loss, 'b', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, train_precision, 'b', label='training precision')\n",
    "plt.plot(epochs, val_precision, 'r', label='valid precision')\n",
    "plt.title('Training and Validation precision')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, train_recall, 'b', label='training recall')\n",
    "plt.plot(epochs, val_recall, 'r', label='valid recall')\n",
    "plt.title('Training and Validation recall')\n",
    "plt.legend()\n",
    "plt.show() \n",
    "\n",
    "plt.plot(epochs, train_auc, 'b', label='training auc')\n",
    "plt.plot(epochs, val_auc, 'r', label='valid auc')\n",
    "plt.title('Training and Validation auc curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmGyOuglHnA5"
   },
   "source": [
    "TESTING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vvsat\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\vvsat\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\vvsat\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4869: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 15s 127ms/step - loss: 0.0861 - acc: 0.9748 - auc_2: 0.9988 - precision_2: 0.9764 - recall_2: 0.9737\n",
      "[test loss, test accuracy]: [0.08610145002603531, 0.9748181104660034, 0.9988029599189758, 0.9764309525489807, 0.9736989140510559]\n"
     ]
    }
   ],
   "source": [
    "#testing the hypermodel on the test dataset\n",
    "eval_result = model.evaluate(test_generator) \n",
    "print(\"[test loss, test accuracy]:\", eval_result)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPQETN8jW-CS"
   },
   "source": [
    "CLASSIFICATION REPORTS AND CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confution Matrix and Classification Report\n",
    "batch_size = 32\n",
    "#developing the predictions for the test dataset\n",
    "Y_pred = model.predict(test_generator, test_generator.samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying the confusion matrix\n",
    "cf_matrix = confusion_matrix(test_generator.classes, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(15,10)) \n",
    "sns.heatmap(cf_matrix, linewidths=1, annot=True, ax=ax, fmt='g') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification Report\n",
    "print('Classification Report') \n",
    "target_names = disease_cls\n",
    "print(classification_report(test_generator.classes, y_pred, target_names=target_names)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(\n",
    "    model, DATASET_PATH, overwrite=True, include_optimizer=True, save_format=None,\n",
    "    signatures=None, options=None, save_traces=True\n",
    ")    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOY6ZEJhB2lP0ZoEQ73k5KI",
   "collapsed_sections": [],
   "name": "alzheimer classifier resnet50.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
